name: Check Sensitive Content in Workflows

on:
  pull_request:
    paths:
      - '.github/workflows/**'
      - 'workflow-templates/**'
  push:
    branches:
      - main
    paths:
      - '.github/workflows/**'
      - 'workflow-templates/**'
  workflow_dispatch:

permissions:
  contents: read
  pull-requests: write

jobs:
  check-sensitive-content:
    name: Scan for Sensitive Content
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v5

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install pyyaml

      - name: Make script executable
        run: chmod +x .github/scripts/check-sensitive-content.py

      - name: Scan workflows for sensitive content
        id: scan
        run: |
          echo "Scanning workflow files for sensitive content..."
          python .github/scripts/check-sensitive-content.py . --json sensitive-content-report.json --fail-on medium
        continue-on-error: true

      - name: Upload scan results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: sensitive-content-report
          path: sensitive-content-report.json
          retention-days: 30

      - name: Comment on PR with results
        if: github.event_name == 'pull_request' && always()
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');
            
            let reportData = { total: 0, by_severity: { CRITICAL: [], HIGH: [], MEDIUM: [], LOW: [] } };
            try {
              const reportContent = fs.readFileSync('sensitive-content-report.json', 'utf8');
              reportData = JSON.parse(reportContent);
            } catch (error) {
              console.log('No report file found or error reading it');
            }
            
            const criticalCount = reportData.by_severity.CRITICAL.length;
            const highCount = reportData.by_severity.HIGH.length;
            const mediumCount = reportData.by_severity.MEDIUM.length;
            const lowCount = reportData.by_severity.LOW.length;
            const total = reportData.total;
            
            let emoji = 'âœ…';
            let status = 'No issues found';
            
            if (criticalCount > 0) {
              emoji = 'ðŸ”´';
              status = 'CRITICAL issues found';
            } else if (highCount > 0) {
              emoji = 'ðŸŸ ';
              status = 'HIGH severity issues found';
            } else if (mediumCount > 0) {
              emoji = 'ðŸŸ¡';
              status = 'MEDIUM severity issues found';
            } else if (lowCount > 0) {
              emoji = 'ðŸ”µ';
              status = 'LOW severity issues found';
            }
            
            let comment = `## ${emoji} Sensitive Content Scan Results\n\n`;
            comment += `**Status:** ${status}\n\n`;
            
            if (total === 0) {
              comment += 'âœ… No sensitive content detected in workflow files.\n\n';
              comment += 'Great job! Your workflow files appear to be following security best practices.\n';
            } else {
              comment += '### Summary\n\n';
              comment += `| Severity | Count |\n`;
              comment += `|----------|-------|\n`;
              comment += `| ðŸ”´ CRITICAL | ${criticalCount} |\n`;
              comment += `| ðŸŸ  HIGH | ${highCount} |\n`;
              comment += `| ðŸŸ¡ MEDIUM | ${mediumCount} |\n`;
              comment += `| ðŸ”µ LOW | ${lowCount} |\n`;
              comment += `| **Total** | **${total}** |\n\n`;
              
              comment += '### Severity Levels\n\n';
              comment += '- ðŸ”´ **CRITICAL**: Hardcoded secrets/credentials - Immediate action required\n';
              comment += '- ðŸŸ  **HIGH**: Potential credential leaks - Should be addressed soon\n';
              comment += '- ðŸŸ¡ **MEDIUM**: Secrets not properly masked - Review recommended\n';
              comment += '- ðŸ”µ **LOW**: Best practice violations - Improvement suggested\n\n';
              
              // Add details for each severity level
              for (const [severity, findings] of Object.entries(reportData.by_severity)) {
                if (findings.length > 0) {
                  const severityEmoji = {
                    'CRITICAL': 'ðŸ”´',
                    'HIGH': 'ðŸŸ ',
                    'MEDIUM': 'ðŸŸ¡',
                    'LOW': 'ðŸ”µ'
                  }[severity];
                  
                  comment += `<details>\n`;
                  comment += `<summary>${severityEmoji} ${severity} Issues (${findings.length})</summary>\n\n`;
                  
                  for (const finding of findings) {
                    comment += `**File:** \`${finding.file}\`\n`;
                    comment += `**Line:** ${finding.line}\n`;
                    comment += `**Issue:** ${finding.description}\n`;
                    comment += `**Content:** \`${finding.content.substring(0, 100)}...\`\n\n`;
                    comment += '---\n\n';
                  }
                  
                  comment += `</details>\n\n`;
                }
              }
              
              comment += '### Recommendations\n\n';
              if (criticalCount > 0 || highCount > 0) {
                comment += 'âš ï¸ **Action Required:** Please review and fix CRITICAL and HIGH severity issues before merging.\n\n';
                comment += '- Remove any hardcoded credentials\n';
                comment += '- Use GitHub Secrets for sensitive values\n';
                comment += '- Ensure proper secret masking in logs\n';
              }
              
              comment += '\nðŸ“„ Full report available in the workflow artifacts.\n';
            }
            
            // Find existing comment
            const { data: comments } = await github.rest.issues.listComments({
              owner: context.repo.owner,
              repo: context.repo.repo,
              issue_number: context.issue.number,
            });
            
            const botComment = comments.find(comment => 
              comment.user.type === 'Bot' && 
              comment.body.includes('Sensitive Content Scan Results')
            );
            
            // Update or create comment
            if (botComment) {
              await github.rest.issues.updateComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                comment_id: botComment.id,
                body: comment
              });
            } else {
              await github.rest.issues.createComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                issue_number: context.issue.number,
                body: comment
              });
            }

      - name: Fail if critical or high severity issues found
        if: steps.scan.outcome == 'failure'
        run: |
          echo "::error::Sensitive content scan failed. Please review the findings above."
          exit 1
